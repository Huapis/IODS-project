#This is a description for the 3rd exercise.
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
# Data source: UCI Machine Learning Repository (http://archive.ics.uci.edu/ml/dataset)
# Metadata available at: https://archive.ics.uci.edu/ml/datasets/Student+Performance
#   The data are from two identical questionaires related to secondary school student alcohol
#   comsumption in Portugal.
# P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance.
paper <- "http://www3.dsi.uminho.pt/pcortez/student.pdf"
source <- "http://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip"
dest <- "~/R/win-library/4.0/IODS-project/data/student.zip"
# Load Data from the web and unzip it
setwd("~/R/win-library/4.0/IODS-project")
download.file(source,dest)
unzip(dest,exdir="~/R/win-library/4.0/IODS-project/data/student")
# Download also the paper in which data were originally used
download.file(paper,"~/R/win-library/4.0/IODS-project/data/student/student.pdf")
# read the datasets into memory
por <- read.table("~/R/win-library/4.0/IODS-project/data/student/student-por.csv", sep = ";", header=TRUE)
math <- read.table("~/R/win-library/4.0/IODS-project/data/student/student-mat.csv", sep = ";", header=TRUE)
# Define own id for both datasets
por_id <- por %>% mutate(id=1000+row_number())
math_id <- math %>% mutate(id=2000+row_number())
# Which columns vary in datasets
free_cols <- c("id","failures","paid","absences","G1","G2","G3")
# The rest of the columns are common identifiers used for joining the datasets
join_cols <- setdiff(colnames(por_id),free_cols)
pormath_free <- por_id %>% bind_rows(math_id) %>% select(one_of(free_cols))
# Combine datasets to one long data
#   NOTE! There are NO 382 but 370 students that belong to both datasets
#         Original joining/merging example is erroneous!
pormath <- por_id %>%
bind_rows(math_id) %>%
# Aggregate data (more joining variables than in the example)
group_by(.dots=join_cols) %>%
# Calculating required variables from two obs
summarise(
n=n(),
id.p=min(id),
id.m=max(id),
failures=round(mean(failures)),     #  Rounded mean for numerical
paid=first(paid),                   #    and first for chars
absences=round(mean(absences)),
G1=round(mean(G1)),
G2=round(mean(G2)),
G3=round(mean(G3))
) %>%
# Remove lines that do not have exactly one obs from both datasets
#   There must be exactly 2 observations found in order to joining be succesful
#   In addition, 2 obs to be joined must be 1 from por and 1 from math
#     (id:s differ more than max within one dataset (649 here))
filter(n==2, id.m-id.p>650) %>%
# Join original free fields, because rounded means or first values may not be relevant
inner_join(pormath_free,by=c("id.p"="id"),suffix=c("",".p")) %>%
inner_join(pormath_free,by=c("id.m"="id"),suffix=c("",".m")) %>%
# Calculate other required variables
ungroup %>% mutate(
alc_use = (Dalc + Walc) / 2,
high_use = alc_use > 2,
cid=3000+row_number()
)
#glimpse of joined and modified dataset
glimpse(pormath)
# use gather() to gather columns into key-value pairs and then glimpse() at the resulting data
gather(pormath) %>% glimpse
# Save created data to folder 'data' as an Excel worksheet
library(openxlsx)
write.xlsx(pormath,file="~/R/win-library/4.0/IODS-project/data/pormath.xlsx")
#Recall created data for check
pormath <- read_excel("data/pormath.xlsx")
#Miikka Haapakoski, 12.11.2020.
#This is a description for the 3rd exercise.
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
# Data source: UCI Machine Learning Repository (http://archive.ics.uci.edu/ml/dataset)
# Metadata available at: https://archive.ics.uci.edu/ml/datasets/Student+Performance
#   The data are from two identical questionaires related to secondary school student alcohol
#   comsumption in Portugal.
# P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance.
paper <- "http://www3.dsi.uminho.pt/pcortez/student.pdf"
source <- "http://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip"
dest <- "~/R/win-library/4.0/IODS-project/data/student.zip"
# Load Data from the web and unzip it
setwd("\\C:\Users\miikk\Documents\IODS-project\data")
download.file(source,dest)
unzip(dest,exdir="\\C:\Users\miikk\Documents\IODS-project\data/student")
#Miikka Haapakoski, 12.11.2020.
#This is a description for the 3rd exercise.
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
# Data source: UCI Machine Learning Repository (http://archive.ics.uci.edu/ml/dataset)
# Metadata available at: https://archive.ics.uci.edu/ml/datasets/Student+Performance
#   The data are from two identical questionaires related to secondary school student alcohol
#   comsumption in Portugal.
# P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance.
paper <- "http://www3.dsi.uminho.pt/pcortez/student.pdf"
source <- "http://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip"
dest <- "~/R/win-library/4.0/IODS-project/data/student.zip"
# Load Data from the web and unzip it
setwd("//C:/Users/miikk/Documents/IODS-project/data")
download.file(source,dest)
unzip(dest,exdir="//C:/Users/miikk/Documents/IODS-project/data/student")
#Miikka Haapakoski, 12.11.2020.
#This is a description for the 3rd exercise.
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
# Data source: UCI Machine Learning Repository (http://archive.ics.uci.edu/ml/dataset)
# Metadata available at: https://archive.ics.uci.edu/ml/datasets/Student+Performance
#   The data are from two identical questionaires related to secondary school student alcohol
#   comsumption in Portugal.
# P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance.
paper <- "http://www3.dsi.uminho.pt/pcortez/student.pdf"
source <- "http://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip"
dest <- "//C:/Users/miikk/Documents/IODS-project/data/student.zip"
# Load Data from the web and unzip it
setwd("//C:/Users/miikk/Documents/IODS-project/data")
download.file(source,dest)
unzip(dest,exdir="//C:/Users/miikk/Documents/IODS-project/data/student")
#Miikka Haapakoski, 12.11.2020.
#This is a description for the 3rd exercise.
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
# Data source: UCI Machine Learning Repository (http://archive.ics.uci.edu/ml/dataset)
# Metadata available at: https://archive.ics.uci.edu/ml/datasets/Student+Performance
#   The data are from two identical questionaires related to secondary school student alcohol
#   comsumption in Portugal.
# P. Cortez and A. Silva. Using Data Mining to Predict Secondary School Student Performance.
paper <- "http://www3.dsi.uminho.pt/pcortez/student.pdf"
source <- "http://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip"
dest <- "//C:/Users/miikk/Documents/IODS-project/data/student.zip"
# Load Data from the web and unzip it
setwd("//C:/Users/miikk/Documents/IODS-project/data")
download.file(source,dest)
unzip(dest,exdir="//C:/Users/miikk/Documents/IODS-project/data/student.zip")
#Miikka Haapakoski, 12.11.2020.
#This is a description for the 3rd exercise.
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
por <- read.table("//C:/Users/miikk/Documents/IODS-project/data/student/student-por.csv", sep = ";", header=TRUE)
math <- read.table("//C:/Users/miikk/Documents/IODS-project/data/student/student-mat.csv", sep = ";", header=TRUE)
#Miikka Haapakoski, 12.11.2020.
#This is a description for the 3rd exercise.
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
por <- read.table("/C:/Users/miikk/Documents/IODS-project/data/student/student-por.csv", sep = ";", header=TRUE)
math <- read.table("/C:/Users/miikk/Documents/IODS-project/data/student/student-mat.csv", sep = ";", header=TRUE)
#Miikka Haapakoski, 12.11.2020.
#This is a description for the 3rd exercise.
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
por <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student\\student-por.csv", sep = ";", header=TRUE)
math <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student\student-mat.csv", sep = ";", header=TRUE)
#Miikka Haapakoski, 12.11.2020.
#This is a description for the 3rd exercise.
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
por <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student\\student-por.csv", sep = ";", header=TRUE)
math <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student\\student-mat.csv", sep = ";", header=TRUE)
#Miikka Haapakoski, 12.11.2020.
#This is a description for the 3rd exercise.
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
por <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student-por.csv", sep = ";", header=TRUE)
math <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student-mat.csv", sep = ";", header=TRUE)
#Miikka Haapakoski, 12.11.2020.
#This is a description for the 3rd exercise.
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
por <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student-por.csv", sep = ";", header=TRUE)
math <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student-mat.csv", sep = ";", header=TRUE)
por_id <- por %>% mutate(id=1000+row_number())
math_id <- math %>% mutate(id=2000+row_number())
#Miikka Haapakoski, 12.11.2020.
#This is a description for the 3rd exercise.
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
por <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student-por.csv", sep = ";", header=TRUE)
math <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student-mat.csv", sep = ";", header=TRUE)
por_id <- por %>% mutate(id=1000+row_number())
math_id <- math %>% mutate(id=2000+row_number())
# Which columns vary in datasets
free_cols <- c("id","failures","paid","absences","G1","G2","G3")
# The rest of the columns are common identifiers used for joining the datasets
join_cols <- setdiff(colnames(por_id),free_cols)
pormath_free <- por_id %>% bind_rows(math_id) %>% select(one_of(free_cols))
# Combine datasets to one long data
#   NOTE! There are NO 382 but 370 students that belong to both datasets
#         Original joining/merging example is erroneous!
pormath <- por_id %>%
bind_rows(math_id) %>%
# Aggregate data (more joining variables than in the example)
group_by(.dots=join_cols) %>%
# Calculating required variables from two obs
summarise(
n=n(),
id.p=min(id),
id.m=max(id),
failures=round(mean(failures)),     #  Rounded mean for numerical
paid=first(paid),                   #    and first for chars
absences=round(mean(absences)),
G1=round(mean(G1)),
G2=round(mean(G2)),
G3=round(mean(G3))
) %>%
# Remove lines that do not have exactly one obs from both datasets
#   There must be exactly 2 observations found in order to joining be succesful
#   In addition, 2 obs to be joined must be 1 from por and 1 from math
#     (id:s differ more than max within one dataset (649 here))
filter(n==2, id.m-id.p>650) %>%
# Join original free fields, because rounded means or first values may not be relevant
inner_join(pormath_free,by=c("id.p"="id"),suffix=c("",".p")) %>%
inner_join(pormath_free,by=c("id.m"="id"),suffix=c("",".m")) %>%
# Calculate other required variables
ungroup %>% mutate(
alc_use = (Dalc + Walc) / 2,
high_use = alc_use > 2,
cid=3000+row_number()
)
#glimpse of joined and modified dataset
glimpse(pormath)
# use gather() to gather columns into key-value pairs and then glimpse() at the resulting data
gather(pormath) %>% glimpse
# Save created data to folder 'data' as an Excel worksheet
library(openxlsx)
write.xlsx(pormath,file="C:\\Users\\miikk\\Documents\\IODS-project\\data\\")
#Recall created data for check
pormath <- read_excel("data/pormath.xlsx")
#Miikka Haapakoski, 12.11.2020.
#This is a description for the 3rd exercise.
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
por <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student-por.csv", sep = ";", header=TRUE)
math <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student-mat.csv", sep = ";", header=TRUE)
por_id <- por %>% mutate(id=1000+row_number())
math_id <- math %>% mutate(id=2000+row_number())
# Which columns vary in datasets
free_cols <- c("id","failures","paid","absences","G1","G2","G3")
# The rest of the columns are common identifiers used for joining the datasets
join_cols <- setdiff(colnames(por_id),free_cols)
pormath_free <- por_id %>% bind_rows(math_id) %>% select(one_of(free_cols))
# Combine datasets to one long data
#   NOTE! There are NO 382 but 370 students that belong to both datasets
#         Original joining/merging example is erroneous!
pormath <- por_id %>%
bind_rows(math_id) %>%
# Aggregate data (more joining variables than in the example)
group_by(.dots=join_cols) %>%
# Calculating required variables from two obs
summarise(
n=n(),
id.p=min(id),
id.m=max(id),
failures=round(mean(failures)),     #  Rounded mean for numerical
paid=first(paid),                   #    and first for chars
absences=round(mean(absences)),
G1=round(mean(G1)),
G2=round(mean(G2)),
G3=round(mean(G3))
) %>%
# Remove lines that do not have exactly one obs from both datasets
#   There must be exactly 2 observations found in order to joining be succesful
#   In addition, 2 obs to be joined must be 1 from por and 1 from math
#     (id:s differ more than max within one dataset (649 here))
filter(n==2, id.m-id.p>650) %>%
# Join original free fields, because rounded means or first values may not be relevant
inner_join(pormath_free,by=c("id.p"="id"),suffix=c("",".p")) %>%
inner_join(pormath_free,by=c("id.m"="id"),suffix=c("",".m")) %>%
# Calculate other required variables
ungroup %>% mutate(
alc_use = (Dalc + Walc) / 2,
high_use = alc_use > 2,
cid=3000+row_number()
)
#glimpse of joined and modified dataset
glimpse(pormath)
# use gather() to gather columns into key-value pairs and then glimpse() at the resulting data
gather(pormath) %>% glimpse
# Save created data to folder 'data' as an Excel worksheet
library(openxlsx)
write.xlsx(pormath,file="C:\\Users\\miikk\\Documents\\IODS-project\\data\\pormath.xlsx")
#Recall created data for check
pormath <- read_excel("data/pormath.xlsx")
#Miikka Haapakoski, 12.11.2020.
#This is a description for the 3rd exercise.
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
por <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student-por.csv", sep = ";", header=TRUE)
math <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student-mat.csv", sep = ";", header=TRUE)
por_id <- por %>% mutate(id=1000+row_number())
math_id <- math %>% mutate(id=2000+row_number())
free_cols <- c("id","failures","paid","absences","G1","G2","G3")
join_cols <- setdiff(colnames(por_id),free_cols)
pormath_free <- por_id %>% bind_rows(math_id) %>% select(one_of(free_cols))
pormath <- por_id %>%
bind_rows(math_id) %>%
group_by(.dots=join_cols) %>%
summarise(
n=n(),
id.p=min(id),
id.m=max(id),
failures=round(mean(failures)),
paid=first(paid),
absences=round(mean(absences)),
G1=round(mean(G1)),
G2=round(mean(G2)),
G3=round(mean(G3))
) %>%
filter(n==2, id.m-id.p>650) %>%
inner_join(pormath_free,by=c("id.p"="id"),suffix=c("",".p")) %>%
inner_join(pormath_free,by=c("id.m"="id"),suffix=c("",".m")) %>%
ungroup %>% mutate(
alc_use = (Dalc + Walc) / 2,
high_use = alc_use > 2,
cid=3000+row_number()
)
glimpse(pormath)
gather(pormath) %>% glimpse
library(openxlsx)
write.xlsx(pormath,file="C:\\Users\\miikk\\Documents\\IODS-project\\data\\pormath.xlsx")
pormath <- read_excel("data/pormath.xlsx")
#Miikka Haapakoski, 12.11.2020.
#This is a description for the 3rd exercise.
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
por <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student-por.csv", sep = ";", header=TRUE)
math <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student-mat.csv", sep = ";", header=TRUE)
por_id <- por %>% mutate(id=1000+row_number())
math_id <- math %>% mutate(id=2000+row_number())
free_cols <- c("id","failures","paid","absences","G1","G2","G3")
join_cols <- setdiff(colnames(por_id),free_cols)
pormath_free <- por_id %>% bind_rows(math_id) %>% select(one_of(free_cols))
pormath <- por_id %>%
bind_rows(math_id) %>%
group_by(.dots=join_cols) %>%
summarise(
n=n(),
id.p=min(id),
id.m=max(id),
failures=round(mean(failures)),
paid=first(paid),
absences=round(mean(absences)),
G1=round(mean(G1)),
G2=round(mean(G2)),
G3=round(mean(G3))
) %>%
filter(n==2, id.m-id.p>650) %>%
inner_join(pormath_free,by=c("id.p"="id"),suffix=c("",".p")) %>%
inner_join(pormath_free,by=c("id.m"="id"),suffix=c("",".m")) %>%
ungroup %>% mutate(
alc_use = (Dalc + Walc) / 2,
high_use = alc_use > 2,
cid=3000+row_number()
)
glimpse(pormath)
gather(pormath) %>% glimpse
library(openxlsx)
write.xlsx(pormath,file="C:\\Users\\miikk\\Documents\\IODS-project\\data\\pormath.xlsx")
pormath <- read_excel("C:\\Users\\miikk\\Documents\\IODS-project\\data\\pormath.xlsx")
#Miikka Haapakoski, 12.11.2020.
#This is a description for the 3rd exercise.
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
por <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student-por.csv", sep = ";", header=TRUE)
math <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student-mat.csv", sep = ";", header=TRUE)
por_id <- por %>% mutate(id=1000+row_number())
math_id <- math %>% mutate(id=2000+row_number())
free_cols <- c("id","failures","paid","absences","G1","G2","G3")
join_cols <- setdiff(colnames(por_id),free_cols)
pormath_free <- por_id %>% bind_rows(math_id) %>% select(one_of(free_cols))
pormath <- por_id %>%
bind_rows(math_id) %>%
group_by(.dots=join_cols) %>%
summarise(
n=n(),
id.p=min(id),
id.m=max(id),
failures=round(mean(failures)),
paid=first(paid),
absences=round(mean(absences)),
G1=round(mean(G1)),
G2=round(mean(G2)),
G3=round(mean(G3))
) %>%
filter(n==2, id.m-id.p>650) %>%
inner_join(pormath_free,by=c("id.p"="id"),suffix=c("",".p")) %>%
inner_join(pormath_free,by=c("id.m"="id"),suffix=c("",".m")) %>%
ungroup %>% mutate(
alc_use = (Dalc + Walc) / 2,
high_use = alc_use > 2,
cid=3000+row_number()
)
glimpse(pormath)
gather(pormath) %>% glimpse
library(openxlsx)
write.xlsx(pormath,file="C:\\Users\\miikk\\Documents\\IODS-project\\data\\pormath.xlsx")
pormath <- read_excel("data/pormath.xlsx")
#Miikka Haapakoski, 12.11.2020.
#This is a description for the 3rd exercise.
library(dplyr)
library(ggplot2)
library(GGally)
library(tidyr)
por <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student-por.csv", sep = ";", header=TRUE)
math <- read.table("C:\\Users\\miikk\\Documents\\IODS-project\\data\\student-mat.csv", sep = ";", header=TRUE)
por_id <- por %>% mutate(id=1000+row_number())
math_id <- math %>% mutate(id=2000+row_number())
free_cols <- c("id","failures","paid","absences","G1","G2","G3")
join_cols <- setdiff(colnames(por_id),free_cols)
pormath_free <- por_id %>% bind_rows(math_id) %>% select(one_of(free_cols))
pormath <- por_id %>%
bind_rows(math_id) %>%
group_by(.dots=join_cols) %>%
summarise(
n=n(),
id.p=min(id),
id.m=max(id),
failures=round(mean(failures)),
paid=first(paid),
absences=round(mean(absences)),
G1=round(mean(G1)),
G2=round(mean(G2)),
G3=round(mean(G3))
) %>%
filter(n==2, id.m-id.p>650) %>%
inner_join(pormath_free,by=c("id.p"="id"),suffix=c("",".p")) %>%
inner_join(pormath_free,by=c("id.m"="id"),suffix=c("",".m")) %>%
ungroup %>% mutate(
alc_use = (Dalc + Walc) / 2,
high_use = alc_use > 2,
cid=3000+row_number()
)
glimpse(pormath)
gather(pormath) %>% glimpse
library(openxlsx)
write.xlsx(pormath,file="C:\\Users\\miikk\\Documents\\IODS-project\\data\\pormath.xlsx")
#Miikka Haapakoski, 12.11.2020.
#This is a description for the 3rd exercise.
library(dplyr)
?tail
?tail
human2014 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human1.txt", sep="\t", header=TRUE")
human2014 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human1.txt", sep="\t", header=TRUE")
#Miikka Haapakoski
#This is the file description
# original data source http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human1.txt
install.packages("dplyr")
library(dplyr)
human2014 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human1.txt", sep="\t", header=TRUE)
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
#Miikka Haapakoski
#05/11/2020
#This is a file description.
learning2014 <- read.table("https://www.mv.helsinki.fi/home/kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header=TRUE)
dim(learning2014)
str(learning2014)
#learning2014 file contains 183 rows and 60 columns. Most of the values are integer, but there are also strings.
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
deep_columns <- select(learning2014, one_of(deep_questions))
learning2014$deep <- rowMeans(deep_columns)
surface_columns <- select(learning2014, one_of(surface_questions))
learning2014$surf <- rowMeans(surface_columns)
strategic_columns <- select(learning2014, one_of(strategic_questions))
learning2014$stra <- rowMeans(strategic_columns)
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
learning2014 <- select(learning2014, one_of(keep_columns))
learning2014 <- filter(learning2014, Points > 0)
setwd("~/IODS-project/data")
write.csv(learning2014, "C:\\Users\\miikk\\Documents\\IODS-project\\data\\learning2014.csv", row.names = TRUE)
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
